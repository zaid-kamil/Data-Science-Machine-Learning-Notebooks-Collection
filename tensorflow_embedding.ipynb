{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"embedding words.ipynb","provenance":[],"authorship_tag":"ABX9TyMeW00RtwPtxG9X5SiNyGeb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"xNL6t2zI-gfb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"52432622-c87a-4965-c9e7-50644e7d653f","executionInfo":{"status":"ok","timestamp":1580614762974,"user_tz":-330,"elapsed":2250,"user":{"displayName":"StormlightX","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA7ffNh8zYCrByq7g6_RvAY6-iNKnGtjnQd5jEkklA=s64","userId":"04862885639735295114"}}},"source":["%tensorflow_version 2.x"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 2.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tEpVw0IW-wo3","colab_type":"code","colab":{}},"source":["import numpy as np\n","import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0yX4dxWo-xKa","colab_type":"code","colab":{}},"source":["corpus_raw = 'He is the king . The king is royal . She is the royal  queen '\n","# convert to lower case\n","corpus_raw = corpus_raw.lower()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WWL-131p_HbJ","colab_type":"text"},"source":["We need to convert this to an input output pair such that if we input a word, it should it predict that the neighbouring words : the n words before and after it, where n is the parameter window_size![alt text](https://miro.medium.com/max/886/1*yiH5sZI-IBxDSQMKhvbcHw.png)"]},{"cell_type":"code","metadata":{"id":"DXd4lJE__FCJ","colab_type":"code","colab":{}},"source":["words = []\n","for word in corpus_raw.split():\n","    if word != '.': # because we don't want to treat . as a word\n","        words.append(word)\n","words = set(words) # so that all duplicate words are removed\n","word2int = {}\n","int2word = {}\n","vocab_size = len(words) # gives the total number of unique words\n","for i,word in enumerate(words):\n","    word2int[word] = i\n","    int2word[i] = word"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NQPuanp8_Alx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"09ee09d4-8baf-41e3-9ef6-6f8284e6d03b","executionInfo":{"status":"ok","timestamp":1580615025000,"user_tz":-330,"elapsed":1221,"user":{"displayName":"StormlightX","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA7ffNh8zYCrByq7g6_RvAY6-iNKnGtjnQd5jEkklA=s64","userId":"04862885639735295114"}}},"source":["word2int"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'he': 3, 'is': 2, 'king': 0, 'queen': 1, 'royal': 4, 'she': 6, 'the': 5}"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"KBV1kk80_v77","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"0da58e67-317d-47c9-a2fb-d278724e13ae","executionInfo":{"status":"ok","timestamp":1580615035832,"user_tz":-330,"elapsed":1160,"user":{"displayName":"StormlightX","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA7ffNh8zYCrByq7g6_RvAY6-iNKnGtjnQd5jEkklA=s64","userId":"04862885639735295114"}}},"source":["int2word"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: 'king', 1: 'queen', 2: 'is', 3: 'he', 4: 'royal', 5: 'the', 6: 'she'}"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"w1yFtar8_1Wp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"6bf5a28b-7aaa-499d-9ea5-8c6ccabb5d2d","executionInfo":{"status":"ok","timestamp":1580615053797,"user_tz":-330,"elapsed":1213,"user":{"displayName":"StormlightX","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA7ffNh8zYCrByq7g6_RvAY6-iNKnGtjnQd5jEkklA=s64","userId":"04862885639735295114"}}},"source":["print(word2int['queen'])"],"execution_count":10,"outputs":[{"output_type":"stream","text":["1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gFQswQp3_6uc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"8eff7ab8-572b-47ec-bb18-1aa3d2e0caff","executionInfo":{"status":"ok","timestamp":1580615083665,"user_tz":-330,"elapsed":1176,"user":{"displayName":"StormlightX","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA7ffNh8zYCrByq7g6_RvAY6-iNKnGtjnQd5jEkklA=s64","userId":"04862885639735295114"}}},"source":["print(int2word[1])"],"execution_count":12,"outputs":[{"output_type":"stream","text":["queen\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tg1PXx_a_8C9","colab_type":"code","colab":{}},"source":["# raw sentences is a list of sentences.\n","raw_sentences = corpus_raw.split('.')\n","sentences = []\n","for sentence in raw_sentences:\n","    sentences.append(sentence.split())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D84nhubUAI3M","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"40e2b812-7456-4891-a07e-09b4b7819b6e","executionInfo":{"status":"ok","timestamp":1580615122247,"user_tz":-330,"elapsed":1129,"user":{"displayName":"StormlightX","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA7ffNh8zYCrByq7g6_RvAY6-iNKnGtjnQd5jEkklA=s64","userId":"04862885639735295114"}}},"source":["sentences"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['he', 'is', 'the', 'king'],\n"," ['the', 'king', 'is', 'royal'],\n"," ['she', 'is', 'the', 'royal', 'queen']]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"PHDnaKXjALXy","colab_type":"code","colab":{}},"source":["data = []\n","WINDOW_SIZE = 2\n","for sentence in sentences:\n","    for word_index, word in enumerate(sentence):\n","        for nb_word in sentence[max(word_index - WINDOW_SIZE, 0) : min(word_index + WINDOW_SIZE, len(sentence)) + 1] : \n","            if nb_word != word:\n","                data.append([word, nb_word])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MTyfM3TYAYS6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":595},"outputId":"aa69a0d3-d576-426c-8b13-024963960b34","executionInfo":{"status":"ok","timestamp":1580615179844,"user_tz":-330,"elapsed":1258,"user":{"displayName":"StormlightX","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA7ffNh8zYCrByq7g6_RvAY6-iNKnGtjnQd5jEkklA=s64","userId":"04862885639735295114"}}},"source":["data"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['he', 'is'],\n"," ['he', 'the'],\n"," ['is', 'he'],\n"," ['is', 'the'],\n"," ['is', 'king'],\n"," ['the', 'he'],\n"," ['the', 'is'],\n"," ['the', 'king'],\n"," ['king', 'is'],\n"," ['king', 'the'],\n"," ['the', 'king'],\n"," ['the', 'is'],\n"," ['king', 'the'],\n"," ['king', 'is'],\n"," ['king', 'royal'],\n"," ['is', 'the'],\n"," ['is', 'king'],\n"," ['is', 'royal'],\n"," ['royal', 'king'],\n"," ['royal', 'is'],\n"," ['she', 'is'],\n"," ['she', 'the'],\n"," ['is', 'she'],\n"," ['is', 'the'],\n"," ['is', 'royal'],\n"," ['the', 'she'],\n"," ['the', 'is'],\n"," ['the', 'royal'],\n"," ['the', 'queen'],\n"," ['royal', 'is'],\n"," ['royal', 'the'],\n"," ['royal', 'queen'],\n"," ['queen', 'the'],\n"," ['queen', 'royal']]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"K7hbKKgYAfiQ","colab_type":"text"},"source":["We have our training data. But it needs to be represented in a way a computer can understand i.e., with numbers. Thatâ€™s where our word2int dict comes handy.\n","\n","\n","```\n","i.e., \n","say we have a vocabulary of 3 words : pen, pineapple, apple\n","where \n","word2int['pen'] -> 0 -> [1 0 0]\n","word2int['pineapple'] -> 1 -> [0 1 0]\n","word2int['apple'] -> 2 -> [0 0 1]\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"veXJFZYNAZVC","colab_type":"code","colab":{}},"source":["# function to convert numbers to one hot vectors\n","def to_one_hot(data_point_index, vocab_size):\n","    temp = np.zeros(vocab_size)\n","    temp[data_point_index] = 1\n","    return temp\n","x_train = [] # input word\n","y_train = [] # output word\n","for data_word in data:\n","    x_train.append(to_one_hot(word2int[ data_word[0] ], vocab_size))\n","    y_train.append(to_one_hot(word2int[ data_word[1] ], vocab_size))\n","# convert them to numpy arrays\n","x_train = np.asarray(x_train)\n","y_train = np.asarray(y_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zV5MAZR3As7i","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":595},"outputId":"19396e03-b243-4184-8e3f-5e35b0ef9cb2","executionInfo":{"status":"ok","timestamp":1580615270981,"user_tz":-330,"elapsed":1204,"user":{"displayName":"StormlightX","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA7ffNh8zYCrByq7g6_RvAY6-iNKnGtjnQd5jEkklA=s64","userId":"04862885639735295114"}}},"source":["print(x_train)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["[[0. 0. 0. 1. 0. 0. 0.]\n"," [0. 0. 0. 1. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 0. 1. 0.]\n"," [1. 0. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 0. 1. 0.]\n"," [1. 0. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 1.]\n"," [0. 0. 0. 0. 0. 0. 1.]\n"," [0. 0. 1. 0. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0. 0.]\n"," [0. 0. 1. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 0. 1. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0.]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HMvdPOmEAvzq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"80a242c3-343b-4519-a5aa-7bcf46c3c0be","executionInfo":{"status":"ok","timestamp":1580615281620,"user_tz":-330,"elapsed":1148,"user":{"displayName":"StormlightX","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA7ffNh8zYCrByq7g6_RvAY6-iNKnGtjnQd5jEkklA=s64","userId":"04862885639735295114"}}},"source":["print(x_train.shape, y_train.shape)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["(34, 7) (34, 7)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fQJ3xsIFAyaz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":180},"outputId":"e75dee8f-0d55-44fe-c66d-214c4afc0ca0","executionInfo":{"status":"error","timestamp":1580615294391,"user_tz":-330,"elapsed":1217,"user":{"displayName":"StormlightX","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA7ffNh8zYCrByq7g6_RvAY6-iNKnGtjnQd5jEkklA=s64","userId":"04862885639735295114"}}},"source":["# making placeholders for x_train and y_train\n","x = tf.placeholder(tf.float32, shape=(None, vocab_size))\n","y_label = tf.placeholder(tf.float32, shape=(None, vocab_size))"],"execution_count":20,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-87ef236e2afd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"]}]},{"cell_type":"markdown","metadata":{"id":"aGEq7Ta6A6sB","colab_type":"text"},"source":["![alt text](https://miro.medium.com/max/1076/1*Os5hj9qg1t6sr0S3DF4gyA.jpeg)"]},{"cell_type":"code","metadata":{"id":"yHPjaXiqA1dL","colab_type":"code","colab":{}},"source":["EMBEDDING_DIM = 5 # you can choose your own number\n","W1 = tf.Variable(tf.random_normal([vocab_size, EMBEDDING_DIM]))\n","b1 = tf.Variable(tf.random_normal([EMBEDDING_DIM])) #bias\n","hidden_representation = tf.add(tf.matmul(x,W1), b1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EG7h_blyBLce","colab_type":"text"},"source":["![alt text](https://miro.medium.com/max/1076/1*cnzY08TWRxG3lMKExbslHw.jpeg)\n","\n","\n","\n","```\n","input_one_hot  --->  embedded repr. ---> predicted_neighbour_prob\n","predicted_prob will be compared against a one hot vector to correct it.\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"T5ZAjbGDBKLL","colab_type":"code","colab":{}},"source":["W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, vocab_size]))\n","b2 = tf.Variable(tf.random_normal([vocab_size]))\n","prediction = tf.nn.softmax(tf.add( tf.matmul(hidden_representation, W2), b2))"],"execution_count":0,"outputs":[]}]}