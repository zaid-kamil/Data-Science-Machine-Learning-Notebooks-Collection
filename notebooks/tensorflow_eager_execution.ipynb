{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 289,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4759,
     "status": "ok",
     "timestamp": 1522926502169,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "2-aWvZR_BsBe",
    "outputId": "94d10369-8519-4916-aa8a-f6d0ebc394ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages\n",
      "Requirement already up-to-date: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow)\n",
      "Requirement already up-to-date: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow)\n",
      "Requirement already up-to-date: tensorboard<1.8.0,>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow)\n",
      "Requirement already up-to-date: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow)\n",
      "Requirement already up-to-date: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow)\n",
      "Requirement already up-to-date: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow)\n",
      "Requirement already up-to-date: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow)\n",
      "Requirement already up-to-date: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow)\n",
      "Requirement already up-to-date: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow)\n",
      "Requirement already up-to-date: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow)\n",
      "Requirement already up-to-date: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow)\n",
      "Requirement already up-to-date: bleach==1.5.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.8.0,>=1.7.0->tensorflow)\n",
      "Requirement already up-to-date: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.8.0,>=1.7.0->tensorflow)\n",
      "Requirement already up-to-date: html5lib==0.9999999 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.8.0,>=1.7.0->tensorflow)\n",
      "Requirement already up-to-date: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.8.0,>=1.7.0->tensorflow)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 105,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5912,
     "status": "ok",
     "timestamp": 1522926508123,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "ESM1DLwSBuU1",
    "outputId": "5a4a9b44-91c4-4255-9c86-32a6951bc6d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "All the files are downloaded\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from zipfile import ZipFile\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "import tensorflow.contrib.eager as tfe\n",
    "\n",
    "\n",
    "def download(url, file):\n",
    "    if not os.path.isfile(file):\n",
    "        print(\"Download file... \" + file + \" ...\")\n",
    "        urlretrieve(url,file)\n",
    "        print(\"File downloaded\")\n",
    "\n",
    "download('https://d17h27t6h515a5.cloudfront.net/topher/2017/February/5898cd6f_traffic-signs-data/traffic-signs-data.zip','data.zip')\n",
    "print(\"All the files are downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 884,
     "status": "ok",
     "timestamp": 1522926509052,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "NCjTM5p3CWId",
    "outputId": "6d671e57-10a4-40ba-fb1e-6b060178c7bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extracted\n",
      "['train.p', 'valid.p', 'test.p']\n"
     ]
    }
   ],
   "source": [
    "def uncompress_features_labels(dir):\n",
    "    if(os.path.isdir('data')):\n",
    "        print('Data extracted')\n",
    "    else:\n",
    "        with ZipFile(dir) as zipf:\n",
    "            zipf.extractall('data')\n",
    "uncompress_features_labels('data.zip')\n",
    "\n",
    "def data_Files(mypath):\n",
    "    onlyfiles = [f for f in os.listdir(mypath) if os.path.isfile(os.path.join(mypath, f))]\n",
    "    print(onlyfiles)\n",
    "\n",
    "data_Files('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 686,
     "status": "ok",
     "timestamp": 1522926509917,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "USYROMc2CsVY",
    "outputId": "ea89e45e-b5be-499b-a7f4-ab3d78a7f6bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded Successfully\n"
     ]
    }
   ],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "\n",
    "# TODO: Fill this in based on where you saved the training and testing data\n",
    "\n",
    "training_file = 'data/train.p'\n",
    "testing_file = 'data/test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "\n",
    "#Flaaten the Images data so that it can be a 1-D array\n",
    "X_train, y_train = train['features'].flatten().reshape(len( train['features']), 1, 3072), train['labels']\n",
    "X_test, y_test = test['features'].flatten().reshape(len( test['features']), 1, 3072), test['labels']\n",
    "print('Data Loaded Successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "8qKtakFxCtjh"
   },
   "outputs": [],
   "source": [
    "#Convert data into float\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "\n",
    "#Convert data into float and take one hot of the output classes\n",
    "y_train = y_train.astype(np.float32) \n",
    "\n",
    "y_train = tf.one_hot(y_train, depth = 43)\n",
    "\n",
    "y_test = tf.one_hot(y_test.astype(np.float32), depth = 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "zm40ZEIyCzFQ"
   },
   "outputs": [],
   "source": [
    "def data(features, labels, batch_size):\n",
    "\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(((features), labels))\n",
    "\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    dataset = dataset.shuffle(100).batch(batch_size)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 255,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 869,
     "status": "ok",
     "timestamp": 1522927076021,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "ys7wYqdRDB1J",
    "outputId": "582cf90a-4583-4cab-97b1-9805f4281e9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[232. 207. 201. ... 122. 119. 105.]]\n",
      "\n",
      " [[ 36.  31.  28. ...  22.  19.  17.]]\n",
      "\n",
      " [[ 80.  91.  98. ...  82.  54.  38.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[240. 220. 197. ... 107. 112.  93.]]\n",
      "\n",
      " [[ 67.  82.  96. ...  44.  33.  24.]]\n",
      "\n",
      " [[ 46.  36.  19. ...  19.  17.  14.]]], shape=(128, 1, 3072), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "dataset = data(X_train, y_train, 128)\n",
    "#get the batch from dataset.\n",
    "features, label = tfe.Iterator(dataset).next()\n",
    "#Print the features from data. Normally this would return a tensor object but with eager execution you can check the values\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hvBYuNV1D7ya"
   },
   "outputs": [],
   "source": [
    "#Declare the model. Note: I know this is not the best model out there:)\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(200, activation=\"tanh\", input_shape=(3072,)),  # input shape required\n",
    "  tf.keras.layers.Dense(100, activation=\"tanh\"),\n",
    "  tf.keras.layers.Dense(43, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gTxrd2I4D83Z"
   },
   "outputs": [],
   "source": [
    "#Declare optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "#Define loss function\n",
    "def loss(model, x, y):\n",
    "  y_ = model(x)\n",
    "  return tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_)\n",
    "#Compute gradient\n",
    "def grad(model, inputs, targets):\n",
    "  with tfe.GradientTape() as tape:\n",
    "    loss_value = loss(model, inputs, targets)\n",
    "  return tape.gradient(loss_value, model.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 102,
     "output_extras": [
      {}
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 53133,
     "status": "ok",
     "timestamp": 1522927255284,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -330
    },
    "id": "mzHA_jT3EQnB",
    "outputId": "3bfba909-1306-4517-d8e7-d351a5216ea5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: Loss: 3.742, Accuracy: 0.977\n",
      "Epoch 001: Loss: 3.743, Accuracy: 0.977\n",
      "Epoch 002: Loss: 3.739, Accuracy: 0.977\n",
      "Epoch 003: Loss: 3.748, Accuracy: 0.977\n",
      "Epoch 004: Loss: 3.711, Accuracy: 0.977\n"
     ]
    }
   ],
   "source": [
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "  epoch_loss_avg = tfe.metrics.Mean()\n",
    "  epoch_accuracy = tfe.metrics.Accuracy()\n",
    "  i = 0\n",
    "  # Training loop - using batches of 32\n",
    "  for x, y in tfe.Iterator(dataset):\n",
    "    # Optimize the model\n",
    "    grads = grad(model, x, y)\n",
    "    optimizer.apply_gradients(zip(grads, model.variables), global_step=tf.train.get_or_create_global_step())\n",
    "    # Track progress\n",
    "    epoch_loss_avg(loss(model, x, y))  # add current batch loss\n",
    "  correct_pred = tf.equal(tf.cast(tf.argmax(model(X_test), axis=1), tf.float32), y_test)\n",
    "  accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "  # end epoch\n",
    "  \n",
    "  print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3f}\".format(epoch, epoch_loss_avg.result(), accuracy))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Eager",
   "provenance": [
    {
     "file_id": "/v2/external/notebooks/welcome.ipynb",
     "timestamp": 1522927575104
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
